{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pints\n",
    "import pints.toy\n",
    "\n",
    "import emupints\n",
    "import emupints.plot as emuplt\n",
    "import emupints.utils as emutils\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import GPy\n",
    "from GPy import kern as kern\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import string\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.87017686,  1.02371723],\n",
       "       [-1.06067642,  0.9984242 ],\n",
       "       [-1.17044491,  0.84221808],\n",
       "       [-0.43302902,  1.00958793],\n",
       "       [-0.67218723,  1.15831525]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load problem from predefined ones\n",
    "model = emupints.Problems.FitzhughNagumoModelDiscontinious\n",
    "problem = emupints.Problems.load_problem(model)\n",
    "\n",
    "problem['values'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take required variables for visualisation\n",
    "n_parameters = problem['n_parameters']\n",
    "log_likelihood = problem['log_likelihood']\n",
    "log_prior = problem['log_prior']\n",
    "log_posterior = problem['log_posterior']\n",
    "bounds = problem['bounds']\n",
    "index_to_param_name = problem['param_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating emulator and specifying variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training size\n",
    "training_size = 500\n",
    "\n",
    "input_parameters = log_prior.sample(training_size)\n",
    "target_likelihoods = np.apply_along_axis(real_log_likelihood, 1, input_parameters)\n",
    "\n",
    "emu = emupints.GPEmulator(real_log_likelihood, \n",
    "                          input_parameters, \n",
    "                          target_likelihoods, \n",
    "                          input_scaler=StandardScaler())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_parameters = emu.n_parameters()\n",
    "\n",
    "kernels = [\n",
    "    kern.Linear(n_parameters)\n",
    "    kern.RBF(n_parameters),\n",
    "    kern.RatQuad(n_parameters),\n",
    "    kern.MLP(n_parameters),\n",
    "    kern.Matern52(n_parameters),\n",
    "    kern.RatQuad(n_parameters) + kern.RBF(n_parameters) * kern.RBF(n_parameters),\n",
    "    kern.Matern52(n_parameters) + kern.RBF(n_parameters) * kern.RBF(n_parameters),\n",
    "    kern.RatQuad(n_parameters) + kern.RBF(n_parameters) + kern.RBF(n_parameters),\n",
    "    kern.MLP(n_parameters) + kern.RBF(n_parameters) + kern.RBF(n_parameters),\n",
    "    kern.MLP(n_parameters) + kern.Matern(n_parameters) + kern.RatQuad(n_parameters),\n",
    "]\n",
    "\n",
    "kernel_names = [emutils.kernel_to_string(kern)]\n",
    "\n",
    "# grid optimization of basic kernels\n",
    "if optimize_hyper_parameters:\n",
    "    \n",
    "    variances = [0.1, 1, 10]\n",
    "    lengthscale = [0.1, 1, 10]\n",
    "\n",
    "    hyper_kernels = [k(n_parameters, variance=v, lengthscale=l)\n",
    "                     for k in [kern.RBF, kern.Matern52, kern.RatQuad]  \n",
    "                     for v in variances\n",
    "                     for l in lengthscale]\n",
    "    hyper_kernels.insert(0, kern.Linear(n_parameters))\n",
    "    hyper_kernels.extend([GPy.kern.MLP(n_parameters, variance = v) for v in variances])\n",
    "    \n",
    "    kernels.extend(hyper_kernels)\n",
    "\n",
    "    kernel_names.extend([emutils.kernel_to_string(kern, decimal_places=2) for kern in hyper_kernels])\n",
    "\n",
    "# kernels that have been optimized for input data\n",
    "trained_kernels = []\n",
    "\n",
    "# possible optimizers: \n",
    "# ‘scg’, ‘lbfgs’, ‘tnc’\n",
    "# can specify max number of iterations using max_iters\n",
    "optimizer = \"lbfgs\"\n",
    "max_iters = 500\n",
    "emu.set_parameters(optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when the output data is normalized values of variance should be small\n",
    "# hence ignore any kernel that has a subkernel \n",
    "# (i.e kernel that is a part of sum/product) \n",
    "# with variance > 10000\n",
    "# set avoid_overfitting to False to stop this effect\n",
    "avoid_overfitting = False\n",
    "variance_threshold = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marginal_likelihoods = []\n",
    "\n",
    "for kernel, kernel_name in zip(kernels, kernel_names):\n",
    "    emu.set_parameters(kernel = kernel)\n",
    "    emu.fit(optimize = False, normalizer = True)\n",
    "    emu.optimize(max_iters = max_iters, messages = False)\n",
    "    \n",
    "    trained_kernel = emu.get_trained_kern()\n",
    "    trained_kernels.append(trained_kernel)\n",
    "    \n",
    "    ml = emu.get_log_marginal_likelihood()\n",
    "    marginal_likelihoods.append(ml)\n",
    "    print(\"{}: {:.2f}\".format(kernel_name, ml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_kernel = None\n",
    "best_score = -1 << 31\n",
    "\n",
    "# find kernel with highest log marginal likelihood\n",
    "for kernel, score in zip(trained_kernels, marginal_likelihoods):\n",
    "    # ignore any overfitting kernel\n",
    "    if avoid_overfitting and emutils.has_high_variance(kernel, threshold = variance_threshold):\n",
    "        continue\n",
    "    # ignore kernels that don't provide the required speed up. at least 5x\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_kernel = kernel\n",
    "        score = best_score\n",
    "        \n",
    "best_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when a kernel consists of many additions / multiplications\n",
    "# utils method kernel_to_string can be useful\n",
    "print(emutils.kernel_to_string(best_kernel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: directly assign kernel to GP in class\n",
    "emu.set_parameters(kernel = best_kernel)\n",
    "emu.fit(optimize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emu.get_gp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_parameters == 2:\n",
    "    # generate data for surfaces\n",
    "    test_splits = 20 # number of splits along each axis\n",
    "    r_grid, k_grid, test_data = emutils.generate_grid(bounds.lower(), \n",
    "                                                      bounds.upper(), \n",
    "                                                      test_splits)    \n",
    "\n",
    "    emu_grid = emutils.predict_grid(emu, test_data)\n",
    "    real_grid = emutils.predict_grid(real_log_likelihood, test_data)\n",
    "\n",
    "    plt.figure(figsize = (10, 5))\n",
    "    ax = emuplt.surface(r_grid, k_grid, emu_grid, \n",
    "                        title = \"True log_likelihood\",\n",
    "                        alpha = 0.8,\n",
    "                        cmap=\"Blues\",\n",
    "                        x_label = \"r (growth rate)\",\n",
    "                        y_label = \"k (carrying capacity)\"\n",
    "                       )\n",
    "\n",
    "    ax.plot_surface(r_grid, k_grid, real_grid, cmap=\"Reds\", alpha = .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_parameters >= 3:\n",
    "    fig, ax = emuplt.plot_fixed_param_grid(\n",
    "        emu,\n",
    "        fixed_parameters,\n",
    "        bounds,\n",
    "        n_splits = axis_n_splits,\n",
    "        shape = (n_parameters, n_parameters - 1),\n",
    "        contour = False,\n",
    "        additional_log_likelihoods = [real_log_likelihood]\n",
    "    )\n",
    "\n",
    "    plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.apply_along_axis(emu, 1, input_parameters).flatten() - target_likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring function for CMA-ES and comparison\n",
    "score = pints.SumOfSquaresError(problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "emu(real_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "real_log_likelihood(real_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running and Timing MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Logistic and Lotka-Voltera use default\n",
    "mcmc_method = None # Adaptive covariance by default\n",
    "# mcmc_method = pints.PopulationMCMC\n",
    "# mcmc_method = pints.MetropolisRandomWalkMCMC\n",
    "# mcmc_method = pints.DifferentialEvolutionMCMC\n",
    "\n",
    "# MCMC parameters\n",
    "num_chains = 3\n",
    "max_iters = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emu_posterior = pints.LogPosterior(emu, log_prior)\n",
    "real_posterior = pints.LogPosterior(real_log_likelihood, log_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible parameter starting points\n",
    "# use three chains\n",
    "# substitute for CMA-ES\n",
    "\n",
    "xs = [\n",
    "    real_parameters * 0.95,\n",
    "    real_parameters * 0.90,\n",
    "    real_parameters * 1.05,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMA-ES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "emu_mcmc = pints.MCMCSampling(emu_posterior, \n",
    "                              num_chains, \n",
    "                              xs, \n",
    "                              method = mcmc_method, \n",
    "                             )\n",
    "emu_mcmc.set_max_iterations(max_iters)\n",
    "emu_mcmc.set_log_to_screen(False)\n",
    "print('Running...')\n",
    "emu_chains = emu_mcmc.run()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# population MCMC\n",
    "real_mcmc = pints.MCMCSampling(real_posterior, \n",
    "                               num_chains, \n",
    "                               xs, \n",
    "                               method = mcmc_method,\n",
    "                              )\n",
    "real_mcmc.set_max_iterations(max_iters)\n",
    "real_mcmc.set_log_to_screen(False)\n",
    "# Run!\n",
    "print('Running...')\n",
    "real_chains = real_mcmc.run()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pints.plot\n",
    "pints.plot.trace(emu_chains)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pints.plot.trace(real_chains)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at likelihood changes along one chain\n",
    "chain = emu_chains[0]\n",
    "emu_prediction = np.apply_along_axis(emu, 1, chain).flatten()\n",
    "real_prediction = np.apply_along_axis(real_log_likelihood, 1, chain).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = range(len(chain))\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Log Likelihood\")\n",
    "plt.plot(iters, emu_prediction, color=\"Red\", label='emu')\n",
    "plt.plot(iters, real_prediction, color=\"Blue\", label='model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pints.MCMCSampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = np.abs(real_prediction - emu_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = np.linspace(0, 10000, len(chain))\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Likelihood difference\")\n",
    "plt.plot(iters, diffs, color = \"Black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
