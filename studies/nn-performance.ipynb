{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pints\n",
    "import pints.toy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import emupints\n",
    "import emupints.plot as emuplt\n",
    "import emupints.utils as emutils\n",
    "import emupints.metrics as emumet\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction time and mae depending on Kernel and problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_NN_emulator(log_likelihood, X, y, model_size):\n",
    "    # save best val model\n",
    "    cp_callback = keras.callbacks.ModelCheckpoint(\"models/nn_performance.hdf5\", \n",
    "                                                  monitor='val_mean_absolute_error', \n",
    "                                                  save_best_only=True, \n",
    "                                                  verbose=0,\n",
    "                                                  save_weights_only=True)\n",
    "    \n",
    "    emu = emupints.NNEmulator(log_likelihood, X, y, \n",
    "                              model_size=model_size,\n",
    "                              input_scaler=MinMaxScaler(feature_range = (-1, 1)),\n",
    "                              output_scaler=StandardScaler(),\n",
    "                             )\n",
    "    emu.set_parameters()\n",
    "    emu.fit(verbose=0, callbacks=[cp_callback])\n",
    "    # restore best\n",
    "    emu._model.load_weights(\"models/nn_performance.hdf5\")\n",
    "    \n",
    "    return emu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic\n",
      "    small: 0.37846, 0.00082, 0.0004236168\n",
      "    average: 0.32411, 0.00070, 0.0004682717\n",
      "    large: 0.80347, 0.00174, 0.0004837585\n",
      "SIR\n",
      "    small: 2.65331, 0.03591, 0.0005174434\n",
      "    average: 1.45928, 0.02014, 0.0005032776\n",
      "    large: 1.39011, 0.01926, 0.0005459108\n",
      "FitzhughNagumo\n",
      "    small: 5.16363, 0.02459, 0.0004996991\n",
      "    average: 4.81941, 0.02701, 0.0006129419\n",
      "    large: 6.24960, 0.03084, 0.0006761247\n",
      "FitzhughNagumoDiscontinious\n",
      "    small: 2.61550, 0.01205, 0.0006767949\n",
      "    average: 4.54474, 0.02117, 0.0005324787\n",
      "    large: 2.53155, 0.01158, 0.0006848132\n",
      "LotkaVolterra\n",
      "    small: 62.84968, 0.08794, 0.0005953986\n",
      "    average: 35.98043, 0.04901, 0.0006190122\n",
      "    large: 42.99322, 0.05853, 0.0005695984\n",
      "LotkaVolterraDiscontinious\n",
      "    small: 56.33616, 0.07832, 0.0005970111\n",
      "    average: 81.46864, 0.11674, 0.0006596515\n",
      "    large: 42.41698, 0.05819, 0.0007689969\n",
      "HodgkinHuxleyIK\n",
      "    small: 2398.79861, 0.02456, 0.0006510672\n",
      "    average: 1762.80199, 0.01803, 0.0007076633\n",
      "    large: 1345.35075, 0.01328, 0.0006921333\n",
      "GoodwinOscillator\n",
      "    small: 34.51828, 0.01408, 0.0006327364\n",
      "    average: 51.19669, 0.02108, 0.0006845714\n",
      "    large: 78.79100, 0.03274, 0.0006499897\n"
     ]
    }
   ],
   "source": [
    "nn_models = ['small', 'average', 'large']\n",
    "\n",
    "train_size = 2000\n",
    "test_size = 400\n",
    "\n",
    "problems = [\n",
    "    (emupints.Problems.LogisticModel, 'Logistic'),\n",
    "    (emupints.Problems.SIRModel, 'SIR'),\n",
    "    (emupints.Problems.FitzhughNagumoModel, 'FitzhughNagumo'),\n",
    "    (emupints.Problems.FitzhughNagumoModelDiscontinious, 'FitzhughNagumoDiscontinious'),\n",
    "    (emupints.Problems.LotkaVolterraModel, 'LotkaVolterra'),\n",
    "    (emupints.Problems.LotkaVolterraModelDiscontinious, 'LotkaVolterraDiscontinious'),\n",
    "    (emupints.Problems.HodgkinHuxleyIKModel, 'HodgkinHuxleyIK'),\n",
    "    (emupints.Problems.GoodwinOscillatorModel, 'GoodwinOscillator'),\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for problem, problem_name in problems:\n",
    "    print(problem_name)\n",
    "    # load problem\n",
    "    problem = emupints.Problems.load_problem(problem)\n",
    "    n_parameters = problem['n_parameters']\n",
    "    log_likelihood = problem['log_likelihood']\n",
    "    log_posterior = problem['log_posterior']\n",
    "    bounds = problem['bounds']\n",
    "    parameters = problem['parameters']\n",
    "\n",
    "    # create data for training and testing\n",
    "    # genera example using normal distribution around parametrs\n",
    "    train_X = parameters + np.random.randn(train_size, n_parameters) * (0.05 * parameters)\n",
    "    train_y = np.apply_along_axis(log_likelihood, 1, train_X)\n",
    "\n",
    "    test_X = parameters + np.random.randn(test_size, n_parameters) * (0.05 * parameters)\n",
    "    test_y = np.apply_along_axis(log_likelihood, 1, test_X)\n",
    "\n",
    "    # metrics to store\n",
    "    model_chain_mae = []\n",
    "    model_chain_mape = []\n",
    "    model_time = []\n",
    "\n",
    "    for model_size in nn_models:\n",
    "        # train emulator\n",
    "        emu = create_NN_emulator(log_likelihood, train_X, train_y, model_size)\n",
    "\n",
    "        # Perform single MCMC run to calcluate chain mape\n",
    "        mcmc = pints.MCMCSampling(\n",
    "            log_posterior, \n",
    "            1, # one chain\n",
    "            [parameters], \n",
    "        )\n",
    "        mcmc.set_max_iterations(20000)\n",
    "        mcmc.set_log_to_screen(False)\n",
    "        mcmc_chain = mcmc.run()[0]\n",
    "    \n",
    "        # accuracy via mae\n",
    "        chain_mae = emumet.chain_mae(mcmc_chain, emu, log_likelihood)\n",
    "        model_chain_mae.append(chain_mae)\n",
    "        \n",
    "        # accuracy via absolute error along a chain \n",
    "        chain_mape = emumet.chain_mape(mcmc_chain, emu, log_likelihood)\n",
    "        model_chain_mape.append(chain_mape)\n",
    "\n",
    "        # speed\n",
    "        pred_time = %timeit -r 50 -o -q emu(parameters)\n",
    "        pred_time = pred_time.average\n",
    "        model_time.append(pred_time)\n",
    "        \n",
    " \n",
    "        # delete used emulators\n",
    "        del emu\n",
    "        \n",
    "        print(\"    {}: {:.5f}, {:.5f}, {:.10f}\".format(model_size, chain_mae, chain_mape, pred_time))\n",
    "    \n",
    "    # store results\n",
    "    results[problem_name] = [model_chain_mae, model_chain_mape, model_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     small    average    large   \n",
      "----------------------------------------------------------------------\n",
      "          Logistic          |mae  |   0.38      0.32      0.80   \n",
      "                            |cmape|   0.08      0.07      0.17   \n",
      "                            |time |  423.62    468.27    483.76  \n",
      "----------------------------------------------------------------------\n",
      "            SIR             |mae  |   2.65      1.46      1.39   \n",
      "                            |cmape|   3.59      2.01      1.93   \n",
      "                            |time |  517.44    503.28    545.91  \n",
      "----------------------------------------------------------------------\n",
      "       FitzhughNagumo       |mae  |   5.16      4.82      6.25   \n",
      "                            |cmape|   2.46      2.70      3.08   \n",
      "                            |time |  499.70    612.94    676.12  \n",
      "----------------------------------------------------------------------\n",
      "FitzhughNagumoDiscontinious |mae  |   2.62      4.54      2.53   \n",
      "                            |cmape|   1.21      2.12      1.16   \n",
      "                            |time |  676.79    532.48    684.81  \n",
      "----------------------------------------------------------------------\n",
      "       LotkaVolterra        |mae  |  62.85     35.98     42.99   \n",
      "                            |cmape|   8.79      4.90      5.85   \n",
      "                            |time |  595.40    619.01    569.60  \n",
      "----------------------------------------------------------------------\n",
      " LotkaVolterraDiscontinious |mae  |  56.34     81.47     42.42   \n",
      "                            |cmape|   7.83     11.67      5.82   \n",
      "                            |time |  597.01    659.65    769.00  \n",
      "----------------------------------------------------------------------\n",
      "      HodgkinHuxleyIK       |mae  | 2398.80   1762.80   1345.35  \n",
      "                            |cmape|   2.46      1.80      1.33   \n",
      "                            |time |  651.07    707.66    692.13  \n",
      "----------------------------------------------------------------------\n",
      "     GoodwinOscillator      |mae  |  34.52     51.20     78.79   \n",
      "                            |cmape|   1.41      2.11      3.27   \n",
      "                            |time |  632.74    684.57    649.99  \n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# print results \n",
    "max_name_len = max([len(name) for _, name in problems])\n",
    "\n",
    "columns = \"\".join([name.center(10) for name in nn_models])\n",
    "columns = \" \" * (max_name_len + 8) + columns\n",
    "print(columns)\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for _, problem_name in problems:\n",
    "    print(problem_name.center(max_name_len), \"|mae  |\", end=\"\")\n",
    "    chain_maes = np.array(results[problem_name][0]) # don't convert\n",
    "    for mae in chain_maes:\n",
    "        print(\"{:.2f}\".format(mae).center(10), end=\"\")\n",
    "    print()\n",
    "    \n",
    "    print(\"\".rjust(max_name_len),\"|cmape|\", end=\"\")\n",
    "    chain_cmaes = np.array(results[problem_name][1]) * 100 # convert to percentages\n",
    "    for cmae in chain_cmaes:\n",
    "        print(\"{:.2f}\".format(cmae).center(10), end=\"\")\n",
    "    print()\n",
    "    \n",
    "    print(\"\".rjust(max_name_len), \"|time |\", end=\"\")\n",
    "    times = np.array(results[problem_name][2]) * 1000000 # convert to micro-seconds\n",
    "    for time in times:\n",
    "        print(\"{:.2f}\".format(time).center(10), end=\"\")\n",
    "    print()\n",
    "    \n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic small: & 0.38 & 0.08 & 423.62\n",
      "Logistic average: & 0.32 & 0.07 & 468.27\n",
      "Logistic large: & 0.80 & 0.17 & 483.76\n",
      "SIR small: & 2.65 & 3.59 & 517.44\n",
      "SIR average: & 1.46 & 2.01 & 503.28\n",
      "SIR large: & 1.39 & 1.93 & 545.91\n",
      "FitzhughNagumo small: & 5.16 & 2.46 & 499.70\n",
      "FitzhughNagumo average: & 4.82 & 2.70 & 612.94\n",
      "FitzhughNagumo large: & 6.25 & 3.08 & 676.12\n",
      "LotkaVolterra small: & 62.85 & 8.79 & 595.40\n",
      "LotkaVolterra average: & 35.98 & 4.90 & 619.01\n",
      "LotkaVolterra large: & 42.99 & 5.85 & 569.60\n",
      "HodgkinHuxleyIK small: & 2398.80 & 2.46 & 651.07\n",
      "HodgkinHuxleyIK average: & 1762.80 & 1.80 & 707.66\n",
      "HodgkinHuxleyIK large: & 1345.35 & 1.33 & 692.13\n",
      "GoodwinOscillator small: & 34.52 & 1.41 & 632.74\n",
      "GoodwinOscillator average: & 51.20 & 2.11 & 684.57\n",
      "GoodwinOscillator large: & 78.79 & 3.27 & 649.99\n"
     ]
    }
   ],
   "source": [
    "problem_names = ['Logistic', 'SIR', 'FitzhughNagumo', 'LotkaVolterra', 'HodgkinHuxleyIK', 'GoodwinOscillator']\n",
    "for problem_name in problem_names:\n",
    "    for i, model_size in enumerate(nn_models):\n",
    "        print(problem_name, model_size, end=\": \")\n",
    "        chain_mae = results[problem_name][0][i]\n",
    "        chain_cmae = results[problem_name][1][i] * 100\n",
    "        time = results[problem_name][2][i] * 1000000\n",
    "        print(\"& {:.2f} & {:.2f} & {:.2f}\".format(chain_mae, chain_cmae, time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAE vs # training points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: small\n",
      "    Size 100: 14873.21742\n",
      "    Size 200: 15869.14623\n",
      "    Size 300: 16203.82843\n",
      "    Size 400: 15903.91234\n",
      "    Size 500: 16397.33722\n",
      "    Size 600: 16020.26178\n",
      "    Size 700: 16237.64469\n",
      "    Size 800: 15586.95076\n",
      "    Size 900: 16205.82755\n",
      "    Size 1000: 15931.97519\n",
      "    Size 1100: 15902.31511\n",
      "    Size 1200: 16102.08523\n",
      "    Size 1300: 16077.25310\n",
      "    Size 1400: 15724.83087\n",
      "    Size 1500: 15988.29022\n",
      "    Size 1600: 16016.54083\n",
      "    Size 1700: 15884.37477\n",
      "    Size 1800: 16186.09995\n",
      "    Size 1900: 15972.02634\n",
      "    Size 2000: 15890.03251\n",
      "    Size 2100: 15887.69518\n",
      "    Size 2200: 15803.56122\n",
      "    Size 2300: 16030.44963\n"
     ]
    }
   ],
   "source": [
    "# Use LotkaVolterra model\n",
    "model = emupints.Problems.HodgkinHuxleyIKModel\n",
    "problem = emupints.Problems.load_problem(model)\n",
    "\n",
    "# take required variables for visualisation\n",
    "n_parameters = problem['n_parameters']\n",
    "log_likelihood = problem['log_likelihood']\n",
    "parameters = problem['parameters']\n",
    "bounds = problem['bounds']\n",
    "\n",
    "\n",
    "# Create data to test\n",
    "train_sizes = [100 * i for i in range(1, 41, 1)]\n",
    "test_size = 1000\n",
    "\n",
    "# create data for training and testing\n",
    "# genera example using normal distribution around parametrs\n",
    "# train_X = parameters + np.random.randn(train_sizes[-1], n_parameters) * (0.05 * parameters)\n",
    "train_X = bounds.sample(train_sizes[-1])\n",
    "train_y = np.apply_along_axis(log_likelihood, 1, train_X)\n",
    "\n",
    "# test_X = parameters + np.random.randn(test_size, n_parameters) * (0.05 * parameters)\n",
    "test_X = bounds.sample(test_size)\n",
    "test_y = np.apply_along_axis(log_likelihood, 1, test_X)\n",
    "\n",
    "# Store results for each kernel in these dicts\n",
    "model_test_mae = {}\n",
    "\n",
    "for model_size in nn_models:\n",
    "    print(\"Model size: \" + model_size)\n",
    "\n",
    "    # store result for each model\n",
    "    emu_mae = []\n",
    "    for size in train_sizes:\n",
    "        X = train_X[:size]\n",
    "        y = train_y[:size]\n",
    "        \n",
    "        emu = create_NN_emulator(log_likelihood, X, y, model_size)\n",
    "        \n",
    "        pred_y = np.apply_along_axis(emu, 1, test_X)\n",
    "        mae = emumet.mae(pred_y, test_y)\n",
    "        \n",
    "        del emu\n",
    "\n",
    "        print(\"    Size {}: {:.5f}\".format(size, mae))\n",
    "    \n",
    "    model_test_mae[model_size] = emu_mae[::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[:100].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
